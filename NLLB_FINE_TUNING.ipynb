{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T10:34:24.265147Z",
     "start_time": "2025-04-20T10:34:24.261004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "import evaluate\n",
    "from datasets import load_dataset"
   ],
   "id": "c0fbfb39da1f3dca",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T10:34:25.545321Z",
     "start_time": "2025-04-20T10:34:25.540971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === CONFIGURATION ===\n",
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "source_lang = \"eng_Latn\"\n",
    "target_lang = \"bul_Cyrl\"\n",
    "source_srt_path = \"data/source.srt\"\n",
    "target_srt_path = \"data/target.srt\"\n",
    "json_output = \"subtitles_dataset.json\"\n",
    "model_output_dir = \"output/nllb_finetuned_subtitles\"\n",
    "epochs = 5\n",
    "batch_size = 4"
   ],
   "id": "a3a91fe87487ac0b",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T10:34:27.366602Z",
     "start_time": "2025-04-20T10:34:27.358983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === STEP 1: Parse SRT files ===\n",
    "def parse_srt(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    blocks = []\n",
    "    current = {'text': ''}\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.isdigit():\n",
    "            if current['text']:\n",
    "                blocks.append(current['text'].strip())\n",
    "                current = {'text': ''}\n",
    "        elif '-->' in line:\n",
    "            continue\n",
    "        elif line:\n",
    "            current['text'] += ' ' + line\n",
    "\n",
    "    if current['text']:\n",
    "        blocks.append(current['text'].strip())\n",
    "\n",
    "    return blocks\n",
    "\n",
    "print(\"ðŸ“¥ Parsing subtitles...\")\n",
    "src_blocks = parse_srt(source_srt_path)\n",
    "tgt_blocks = parse_srt(target_srt_path)\n",
    "print(\"Done parsing the subtitle.\")\n",
    "\n",
    "# Create JSONL dataset\n",
    "with open(json_output, \"w\", encoding=\"utf-8\") as f:\n",
    "    for src, tgt in zip(src_blocks, tgt_blocks):\n",
    "        json.dump({\"translation\": {\"src\": src, \"tgt\": tgt}}, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")"
   ],
   "id": "57d5a2eb04645263",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Parsing subtitles...\n",
      "Done parsing the subtitle.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T10:34:30.729911Z",
     "start_time": "2025-04-20T10:34:30.222892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === STEP 2: Load and split dataset ===\n",
    "print(\"ðŸ“Š Loading dataset...\")\n",
    "dataset = load_dataset(\"json\", data_files=json_output, split=\"train\")\n",
    "dataset_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "test_dataset = dataset_split[\"test\"]\n",
    "\n",
    "print(\"Training dataset: \", train_dataset)\n",
    "print(\"Test dataset: \", test_dataset)"
   ],
   "id": "7b49e13b2d81fe6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Loading dataset...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfa287242c3747278202faba49d8a13e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  Dataset({\n",
      "    features: ['translation'],\n",
      "    num_rows: 5\n",
      "})\n",
      "Test dataset:  Dataset({\n",
      "    features: ['translation'],\n",
      "    num_rows: 2\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T10:52:18.029952Z",
     "start_time": "2025-04-20T10:52:15.769333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === STEP 3: Tokenization ===\n",
    "print(\"ðŸ§  Tokenizing...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, src_lang=source_lang, tgt_lang=target_lang)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    # Extract texts from the batch (already comes as lists)\n",
    "    src_texts = [item['src'] for item in batch['translation']]\n",
    "    tgt_texts = [item['tgt'] for item in batch['translation']]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        src_texts,\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            tgt_texts,\n",
    "            max_length=128,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "    model_inputs[\"labels\"] = [\n",
    "        [token if token != tokenizer.pad_token_id else -100 for token in label_seq]\n",
    "        for label_seq in labels\n",
    "    ]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# Update dataset mapping with error handling\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "\n",
    "try:\n",
    "    train_dataset = train_dataset.map(\n",
    "        tokenize_fn,\n",
    "        batched=True,\n",
    "        remove_columns=train_dataset.column_names\n",
    "    )\n",
    "    test_dataset = test_dataset.map(\n",
    "        tokenize_fn,\n",
    "        batched=True,\n",
    "        remove_columns=test_dataset.column_names\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error during tokenization: {str(e)}\")\n",
    "    raise"
   ],
   "id": "840b8aae2f6139f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Tokenizing...\n",
      "Dataset({\n",
      "    features: ['translation'],\n",
      "    num_rows: 5\n",
      "})\n",
      "Dataset({\n",
      "    features: ['translation'],\n",
      "    num_rows: 2\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9f0ad4aaa88406eb05ae03bcf4ded64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe0c74500cf64c7eb6b7a2de28ed0d8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T11:01:04.015115Z",
     "start_time": "2025-04-20T10:57:32.246246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === STEP 4: Training Setup ===\n",
    "print(\"ðŸ‹ï¸ Starting training setup...\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=model_output_dir,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,  # Set False if you don't use GPU\n",
    ")\n",
    "\n",
    "bleu = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    return bleu.compute(predictions=decoded_preds, references=[[lbl] for lbl in decoded_labels])\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === STEP 5: Train ===\n",
    "print(\"ðŸš€ Training...\")\n",
    "trainer.train()\n",
    "\n",
    "# === STEP 6: Save Model ===\n",
    "print(\"ðŸ’¾ Saving fine-tuned model...\")\n",
    "trainer.save_model(model_output_dir)\n",
    "tokenizer.save_pretrained(model_output_dir)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "4fd2444985bf3c89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‹ï¸ Starting training setup...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Murti\\AppData\\Local\\Temp\\ipykernel_3324\\912193657.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3/10 00:47 < 05:30, 0.02 it/s, Epoch 1/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\GitHub\\NLLB-200-Fine-Tuning-on-Subtitles\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[47]\u001B[39m\u001B[32m, line 35\u001B[39m\n\u001B[32m     33\u001B[39m \u001B[38;5;66;03m# === STEP 5: Train ===\u001B[39;00m\n\u001B[32m     34\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mðŸš€ Training...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[38;5;66;03m# === STEP 6: Save Model ===\u001B[39;00m\n\u001B[32m     38\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mðŸ’¾ Saving fine-tuned model...\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\GitHub\\NLLB-200-Fine-Tuning-on-Subtitles\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2245\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2243\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2244\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2246\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2247\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2248\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2249\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2250\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\GitHub\\NLLB-200-Fine-Tuning-on-Subtitles\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2661\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2658\u001B[39m     \u001B[38;5;28mself\u001B[39m.control.should_training_stop = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m   2660\u001B[39m \u001B[38;5;28mself\u001B[39m.control = \u001B[38;5;28mself\u001B[39m.callback_handler.on_epoch_end(args, \u001B[38;5;28mself\u001B[39m.state, \u001B[38;5;28mself\u001B[39m.control)\n\u001B[32m-> \u001B[39m\u001B[32m2661\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_maybe_log_save_evaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2662\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtr_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_time\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlearning_rate\u001B[49m\n\u001B[32m   2663\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2665\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m DebugOption.TPU_METRICS_DEBUG \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.debug:\n\u001B[32m   2666\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_torch_xla_available():\n\u001B[32m   2667\u001B[39m         \u001B[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\GitHub\\NLLB-200-Fine-Tuning-on-Subtitles\\.venv\\Lib\\site-packages\\transformers\\trainer.py:3103\u001B[39m, in \u001B[36mTrainer._maybe_log_save_evaluate\u001B[39m\u001B[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001B[39m\n\u001B[32m   3100\u001B[39m         \u001B[38;5;28mself\u001B[39m.control.should_save = is_new_best_metric\n\u001B[32m   3102\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.control.should_save:\n\u001B[32m-> \u001B[39m\u001B[32m3103\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_save_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3104\u001B[39m     \u001B[38;5;28mself\u001B[39m.control = \u001B[38;5;28mself\u001B[39m.callback_handler.on_save(\u001B[38;5;28mself\u001B[39m.args, \u001B[38;5;28mself\u001B[39m.state, \u001B[38;5;28mself\u001B[39m.control)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\GitHub\\NLLB-200-Fine-Tuning-on-Subtitles\\.venv\\Lib\\site-packages\\transformers\\trainer.py:3200\u001B[39m, in \u001B[36mTrainer._save_checkpoint\u001B[39m\u001B[34m(self, model, trial)\u001B[39m\n\u001B[32m   3198\u001B[39m run_dir = \u001B[38;5;28mself\u001B[39m._get_output_dir(trial=trial)\n\u001B[32m   3199\u001B[39m output_dir = os.path.join(run_dir, checkpoint_folder)\n\u001B[32m-> \u001B[39m\u001B[32m3200\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msave_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_internal_call\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   3202\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.save_strategy \u001B[38;5;129;01min\u001B[39;00m [SaveStrategy.STEPS, SaveStrategy.EPOCH] \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.state.best_global_step:\n\u001B[32m   3203\u001B[39m     best_checkpoint_folder = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mPREFIX_CHECKPOINT_DIR\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.state.best_global_step\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\GitHub\\NLLB-200-Fine-Tuning-on-Subtitles\\.venv\\Lib\\site-packages\\transformers\\trainer.py:3902\u001B[39m, in \u001B[36mTrainer.save_model\u001B[39m\u001B[34m(self, output_dir, _internal_call)\u001B[39m\n\u001B[32m   3899\u001B[39m         \u001B[38;5;28mself\u001B[39m.model_wrapped.save_checkpoint(output_dir)\n\u001B[32m   3901\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.should_save:\n\u001B[32m-> \u001B[39m\u001B[32m3902\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3904\u001B[39m \u001B[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001B[39;00m\n\u001B[32m   3905\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.push_to_hub \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _internal_call:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\GitHub\\NLLB-200-Fine-Tuning-on-Subtitles\\.venv\\Lib\\site-packages\\transformers\\trainer.py:4006\u001B[39m, in \u001B[36mTrainer._save\u001B[39m\u001B[34m(self, output_dir, state_dict)\u001B[39m\n\u001B[32m   4004\u001B[39m             torch.save(state_dict, os.path.join(output_dir, WEIGHTS_NAME))\n\u001B[32m   4005\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m4006\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4007\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msafe_serialization\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave_safetensors\u001B[49m\n\u001B[32m   4008\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4010\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.processing_class \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   4011\u001B[39m     \u001B[38;5;28mself\u001B[39m.processing_class.save_pretrained(output_dir)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\GitHub\\NLLB-200-Fine-Tuning-on-Subtitles\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3564\u001B[39m, in \u001B[36mPreTrainedModel.save_pretrained\u001B[39m\u001B[34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001B[39m\n\u001B[32m   3559\u001B[39m     gc.collect()\n\u001B[32m   3561\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m safe_serialization:\n\u001B[32m   3562\u001B[39m     \u001B[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001B[39;00m\n\u001B[32m   3563\u001B[39m     \u001B[38;5;66;03m# joyfulness), but for now this enough.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3564\u001B[39m     safe_save_file(shard, os.path.join(save_directory, shard_file), metadata={\u001B[33m\"\u001B[39m\u001B[33mformat\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m})\n\u001B[32m   3565\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   3566\u001B[39m     save_function(shard, os.path.join(save_directory, shard_file))\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T16:20:51.725266Z",
     "start_time": "2025-04-20T16:20:42.665019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"ðŸ§ª Running a test translation...\")\n",
    "test_text = \"Where are you going?\"\n",
    "\n",
    "# Set source and target languages\n",
    "tokenizer.src_lang = source_lang\n",
    "\n",
    "# Tokenize input text\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
    "\n",
    "# Get the target language token ID\n",
    "forced_bos_token_id = tokenizer.convert_tokens_to_ids(target_lang)\n",
    "\n",
    "# Generate translation\n",
    "generated = model.generate(**inputs, forced_bos_token_id=forced_bos_token_id)\n",
    "\n",
    "# Decode and print\n",
    "print(\"ðŸ”¤ Translation:\", tokenizer.decode(generated[0], skip_special_tokens=True))\n"
   ],
   "id": "9a1af99a0decbba9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Running a test translation...\n",
      "ðŸ”¤ Translation: ÐšÑŠÐ´Ðµ Ð¾Ñ‚Ð¸Ð²Ð°Ñˆ? - Ð”Ð°.\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Path to the saved fine-tuned model\n",
    "model_path = \"output/nllb_finetuned_subtitles\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "# Example input sentence\n",
    "text = \"Where are you going?\"\n",
    "\n",
    "# Set language codes\n",
    "source_lang = \"eng_Latn\"\n",
    "target_lang = \"bul_Cyrl\"\n",
    "\n",
    "# Tokenize input\n",
    "tokenizer.src_lang = source_lang  # set the source language\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get token ID for the target language\n",
    "forced_bos_token_id = tokenizer.convert_tokens_to_ids(target_lang)\n",
    "\n",
    "# Generate translation\n",
    "generated_tokens = model.generate(\n",
    "    **inputs,\n",
    "    forced_bos_token_id=forced_bos_token_id\n",
    ")\n",
    "\n",
    "# Decode translation\n",
    "translation = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "print(\"Translation:\", translation)"
   ],
   "id": "6246f6cb2bf12993"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "he directory nllb_finetuned_subtitles/ must contain:\n",
    "\n",
    "    pytorch_model.bin\n",
    "\n",
    "    config.json\n",
    "\n",
    "    tokenizer.json\n",
    "\n",
    "    tokenizer_config.json\n",
    "\n",
    "    special_tokens_map.json"
   ],
   "id": "2899c505250c1b42"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
